{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/BigDataGal/Python-for-Data-Science/master/titanic-train.csv\"\n",
    "titanic_train = pd.read_csv(url)\n",
    "\n",
    "print(titanic_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "print(titanic_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the Age and Cabin column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train[\"Age\"] = titanic_train[\"Age\"].fillna(titanic_train[\"Age\"].median())\n",
    "titanic_train[\"Embarked\"] = titanic_train[\"Embarked\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert sex and Embarked classes to dummy variables using OHE and drop target and unhelpful columns\n",
    "candidate_train_predictors = titanic_train.drop(['PassengerId', 'Survived', 'Name', 'Ticket'], axis = 1)\n",
    "\n",
    "categorical_cols = [cname for cname in candidate_train_predictors.columns if candidate_train_predictors[cname].nunique()<10 and candidate_train_predictors[cname].dtype == \"object\"]\n",
    "numeric_cols = [cname for cname in candidate_train_predictors.columns if candidate_train_predictors[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "my_cols = categorical_cols + numeric_cols\n",
    "train_predictors = candidate_train_predictors[my_cols]\n",
    "\n",
    "dummy_encoded_train_predictors = pd.get_dummies(train_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3. 22.  1. ...  0.  0.  1.]\n",
      " [ 1. 38.  1. ...  1.  0.  0.]\n",
      " [ 3. 26.  0. ...  0.  0.  1.]\n",
      " ...\n",
      " [ 3. 28.  1. ...  0.  0.  1.]\n",
      " [ 1. 26.  0. ...  1.  0.  0.]\n",
      " [ 3. 32.  0. ...  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#Create the target and features numpy arrays: target, features_one\n",
    "y_target = titanic_train[\"Survived\"].values\n",
    "x_features_one = dummy_encoded_train_predictors.values\n",
    "print(x_features_one)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets - 3:4\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_features_one, y_target, test_size =.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_one = tree.DecisionTreeClassifier()\n",
    "tree_one = tree_one.fit(x_features_one, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9798\n"
     ]
    }
   ],
   "source": [
    "#Look at the score of the included features\n",
    "tree_one_accuracy = round(tree_one.score(x_features_one, y_target), 4)\n",
    "print(\"Accuracy: %0.4f\" % (tree_one_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128,   0],\n",
       "       [  8,  87]], dtype=int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict y_target given validation set\n",
    "predictions = tree_one.predict(x_validation)\n",
    "# Look at the confusion matrix\n",
    "confusion_matrix(y_validation,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9641255605381166"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_validation, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting and additional features\n",
    "# Create the target and features numpy arrays: target, features_two\n",
    "y_target = titanic_train[\"Survived\"].values\n",
    "x_features_two = dummy_encoded_train_predictors.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9798\n"
     ]
    }
   ],
   "source": [
    "tree_two = tree.DecisionTreeClassifier()\n",
    "tree_two = tree_two.fit(x_features_two, y_target)\n",
    "\n",
    "tree_two_accuracy = round(tree_two.score(x_features_two, y_target), 4)\n",
    "print(\"Accuracy: %0.4f\" % (tree_two_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9091\n"
     ]
    }
   ],
   "source": [
    "max_depth = 10\n",
    "min_samples_split = 5\n",
    "tree_two = tree.DecisionTreeClassifier(max_depth = max_depth, min_samples_split = min_samples_split, random_state = 1)\n",
    "tree_two = tree_two.fit(x_features_two, y_target)\n",
    "\n",
    "# Look at the score of the included features\n",
    "tree_two_accuracy = round(tree_two.score(x_features_two, y_target), 4)\n",
    "print(\"Accuracy: %0.4f\" % (tree_two_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "titanic_train['family_size'] = 1 + titanic_train['SibSp'] + titanic_train['Parch']\n",
    "\n",
    "candidate_train_predictors = titanic_train.drop(['PassengerId','Survived','Name','Ticket','Cabin','SibSp','Parch'], axis = 1)\n",
    "categorical_cols = [cname for cname in candidate_train_predictors.columns if candidate_train_predictors[cname].nunique() < 10 and candidate_train_predictors[cname].dtype == \"object\"]\n",
    "numeric_cols = [cname for cname in candidate_train_predictors.columns if candidate_train_predictors[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "my_cols = categorical_cols + numeric_cols\n",
    "train_predictors = candidate_train_predictors[my_cols]\n",
    "\n",
    "dummy_encoded_train_predictors = pd.get_dummies(train_predictors)\n",
    "\n",
    "# Create the target and features numpy arrays: target, features_three\n",
    "y_target = titanic_train[\"Survived\"].values\n",
    "x_features_three = dummy_encoded_train_predictors.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_three = tree.DecisionTreeClassifier()\n",
    "tree_three = tree_three.fit(x_features_three, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9798\n"
     ]
    }
   ],
   "source": [
    "# Look at the score of the included features\n",
    "tree_three_accuracy = round(tree_three.score(x_features_three, y_target), 4)\n",
    "print(\"Accuracy: %0.4f\" % (tree_three_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Control overfitting by setting \"max_depth\" to 10 and \"min_samples_split\" to 5\n",
    "max_depth = 10\n",
    "min_samples_split = 5\n",
    "tree_three = tree.DecisionTreeClassifier(max_depth = max_depth, min_samples_split = min_samples_split, random_state = 1)\n",
    "tree_three = tree_three.fit(x_features_three, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "print(tree_three.score(x_features_three, y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
